1
00:00:28,247 --> 00:00:31,247
Hello OHBM 2020 Open Science Room!

2
00:00:31,600 --> 00:00:35,436
I'm here with an update on the
MNE-Python project

3
00:00:36,512 --> 00:00:41,991
MNE-Python is an advanced analysis package
for time series neuroimaging data

4
00:00:42,007 --> 00:00:48,000
such as MEG, EEG, ECoG and fNIRS.

5
00:00:49,745 --> 00:00:52,356
Whatever your needs are for
pre-processing your data

6
00:00:52,381 --> 00:00:55,622
chances are good that MNE-Python can do it.

7
00:00:58,454 --> 00:01:01,501
Let's take a look at some of the things it can do...

8
00:01:01,526 --> 00:01:04,354
We can annotate bad channels

9
00:01:06,923 --> 00:01:08,923
bad segments

10
00:01:12,389 --> 00:01:14,389
bad epochs

11
00:01:18,471 --> 00:01:25,285
and MNE-Python now contains a complete
implementation of MEG-IN's maxfilter.

12
00:01:28,948 --> 00:01:31,177
You can compute independent components

13
00:01:31,214 --> 00:01:33,987
so you can get rid of eye and heart artifacts

14
00:01:36,387 --> 00:01:38,387
cut epochs

15
00:01:40,427 --> 00:01:42,427
annotate them with meta-data

16
00:01:43,537 --> 00:01:45,294
and study evoked activity

17
00:01:45,319 --> 00:01:48,915
Any. Way. You. Like.

18
00:01:50,808 --> 00:01:54,425
And when it's time to localize
the actual sources in the brain...

19
00:01:54,866 --> 00:01:59,733
Perform co-registration between
your sensors and an MRI scan.

20
00:02:01,848 --> 00:02:03,848
Construct BEM models.

21
00:02:04,662 --> 00:02:06,662
Define a source space.

22
00:02:07,838 --> 00:02:10,502
And compute the lead field.

23
00:02:11,115 --> 00:02:13,672
And when it comes to the
actual source localization...

24
00:02:18,402 --> 00:02:23,784
There are so many ways to do it!

25
00:02:25,029 --> 00:02:29,131
Use cluster permutation testing
for group level statistics.

26
00:02:29,233 --> 00:02:32,326
And so much more!

27
00:02:35,495 --> 00:02:38,463
Now, let's take a look at what we've been adding

28
00:02:38,518 --> 00:02:41,103
since last we saw each other at OHBM.

29
00:02:41,865 --> 00:02:43,783
We've implemented the missing pieces

30
00:02:43,783 --> 00:02:46,732
to make our open source maxfilter implementation

31
00:02:46,749 --> 00:02:49,717
just as good as the commercial MEG-IN version

32
00:02:50,157 --> 00:02:54,333
And this means we now support
continuous head position tracking

33
00:02:54,333 --> 00:02:56,333
and correct for it.

34
00:02:58,465 --> 00:03:04,191
You can use maxfilter for automatic
bad channel detection of your MEG data.

35
00:03:05,338 --> 00:03:08,531
Our co-registration GUI
has gotten some love as well.

36
00:03:08,531 --> 00:03:13,134
It will now attempt to automatically detect
the MRI fiducials.

37
00:03:13,574 --> 00:03:15,684
It doesn't always work,
but when it does

38
00:03:15,684 --> 00:03:19,502
your co-registration can be performed
completely automatic.

39
00:03:21,261 --> 00:03:23,926
Our topomap plots are looking better then ever.

40
00:03:24,058 --> 00:03:29,118
We've overhauled how we detect the head position
and deal with subsets of sensors.

41
00:03:29,204 --> 00:03:30,589
And speaking of sensors...

42
00:03:30,589 --> 00:03:34,215
You can now visualize
sensor-to-sensor connectivity in 3D.

43
00:03:34,818 --> 00:03:37,670
We also support more file formats than ever.

44
00:03:37,803 --> 00:03:39,582
Including: Curry files...

45
00:03:39,582 --> 00:03:42,832
The new NYU 2019 KIT system...

46
00:03:42,865 --> 00:03:47,206
And we can import independent components
straight from EEGLAB.

47
00:03:47,411 --> 00:03:49,090
We're also faster than ever

48
00:03:49,115 --> 00:03:52,438
with speed improvements all over the code base.

49
00:03:53,251 --> 00:03:55,611
And finally... there's one more thing...

50
00:04:02,277 --> 00:04:07,441
A completely new visualizer for source activity,
based on PyVista!

51
00:04:09,149 --> 00:04:12,292
You can scroll smoothly through time

52
00:04:13,313 --> 00:04:16,451
or just press the spacebar to play it as a movie.

53
00:04:17,356 --> 00:04:20,183
You can quickly adjust color thresholds.

54
00:04:21,327 --> 00:04:26,897
And click on any vertex
to get a plot of the time course.

55
00:04:34,583 --> 00:04:38,529
But MNE-Python is more than
just a fantastic piece of software.

56
00:04:38,855 --> 00:04:42,121
Above all, we are a community of scientists

57
00:04:42,332 --> 00:04:46,121
sharing our expertise,
so that every one of us benefits.

58
00:04:46,323 --> 00:04:50,028
Every time we solve a problem,
or find a better way to do things

59
00:04:50,090 --> 00:04:53,036
all of our analysis pipelines improve a little.

60
00:04:53,145 --> 00:04:57,841
Our GitHub page is always buzzing
with issues and pull requests.

61
00:04:58,182 --> 00:05:00,955
Come take a look
and see what we're working on next!

62
00:05:01,048 --> 00:05:03,330
Even better: please join in!

63
00:05:03,473 --> 00:05:08,914
We encourage everyone to file new bug reports
and contibute pull requests with new features.

64
00:05:09,008 --> 00:05:12,192
Alex and Eric are usually
the first ones to respond.

65
00:05:12,443 --> 00:05:14,628
Become a contributer to MNE-Python

66
00:05:14,628 --> 00:05:16,499
and you will improve your programming skills

67
00:05:16,499 --> 00:05:17,860
you will make new friends

68
00:05:17,885 --> 00:05:21,404
and you will find that when you put in some effort
to help other people

69
00:05:21,505 --> 00:05:24,368
others will gladly put in effort to help you.

70
00:05:25,031 --> 00:05:28,718
You don't have to solve every problem by yourself.

71
00:05:28,994 --> 00:05:30,944
Come join us!

